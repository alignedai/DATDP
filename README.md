# DATDP

Defence Against The Dark Prompts

Run the code in the following way:

```
forbidden_assessment.py --model MODEL --input_file INPUT_FILE [--output_file OUTPUT_FILE]
```

```MODEL``` can be any model that can be run with ```AutoTokenizer``` and ```AutoModelForCausalLM```. The prompts have been optimised for LLaMa-3, however.
